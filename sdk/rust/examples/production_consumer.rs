use futures::StreamExt;
use rustmq_client::{config::StartPosition, *};
use std::sync::atomic::Ordering;
use std::time::Duration;
use tokio;
use tracing_subscriber;

/// Comprehensive example demonstrating the enhanced RustMQ Consumer
/// with production-ready features including:
/// - Task management and proper resource cleanup
/// - Message caching for effective retry functionality
/// - Circuit breaker for broker failure protection
/// - Batch acknowledgment processing for improved performance
/// - Comprehensive metrics and monitoring
#[tokio::main]
async fn main() -> Result<()> {
    // Initialize structured logging with appropriate level
    tracing_subscriber::fmt()
        .with_level(true)
        .with_target(true)
        .init();

    println!("ðŸš€ Starting Production-Ready RustMQ Consumer Example");

    // Create production-grade client configuration
    let config = ClientConfig {
        brokers: vec!["localhost:9092".to_string()],
        client_id: Some("production-consumer-demo".to_string()),
        request_timeout: Duration::from_secs(30),
        connect_timeout: Duration::from_secs(10),
        keep_alive_interval: Duration::from_secs(30),
        max_connections: 5,
        retry_config: RetryConfig {
            max_retries: 3,
            base_delay: Duration::from_millis(100),
            max_delay: Duration::from_secs(5),
            multiplier: 2.0,
            jitter: true,
        },
        ..Default::default()
    };

    // Create client with production configuration
    let client = RustMqClient::new(config).await?;
    println!("âœ… Connected to RustMQ cluster");

    // Configure production consumer with optimized settings
    let consumer_config = ConsumerConfig {
        consumer_id: Some("production-consumer-v1".to_string()),
        consumer_group: "production-processing-group".to_string(),

        // Optimize for performance and reliability
        enable_auto_commit: false, // Manual commit for guaranteed processing
        auto_commit_interval: Duration::from_secs(5),

        // Batch fetching for better throughput
        fetch_size: 500,
        fetch_timeout: Duration::from_millis(100),

        // Start from earliest for complete processing
        start_position: StartPosition::Latest,

        // Enhanced error handling
        max_retry_attempts: 5,
        dead_letter_queue: Some("production-dlq".to_string()),
    };

    // Create production consumer with enhanced capabilities
    let consumer = ConsumerBuilder::new()
        .topic("production-events")
        .consumer_group("production-processing-group")
        .config(consumer_config)
        .client(client.clone())
        .build()
        .await?;

    println!("âœ… Created production consumer with enhanced features");
    println!("   - Task Management: Background task coordination");
    println!("   - Message Caching: LRU cache for retry functionality");
    println!("   - Circuit Breaker: Automatic broker failure protection");
    println!("   - Batch Processing: Acknowledgment batching for performance");

    // Start comprehensive monitoring
    start_production_monitoring(&consumer).await;

    // Demonstrate production consumption patterns
    println!("\nðŸ”„ Starting production consumption patterns...");

    // Pattern 1: High-throughput batch processing
    println!("\n--- Pattern 1: High-Throughput Batch Processing ---");
    demonstrate_batch_processing(&consumer).await?;

    // Pattern 2: Resilient processing with circuit breaker
    println!("\n--- Pattern 2: Resilient Processing ---");
    demonstrate_resilient_processing(&consumer).await?;

    // Pattern 3: Advanced partition management
    println!("\n--- Pattern 3: Advanced Partition Management ---");
    demonstrate_advanced_partition_management(&consumer).await?;

    // Pattern 4: Performance-optimized streaming
    println!("\n--- Pattern 4: Performance-Optimized Streaming ---");
    demonstrate_optimized_streaming(&consumer).await?;

    // Pattern 5: Production metrics and observability
    println!("\n--- Pattern 5: Production Metrics ---");
    demonstrate_production_metrics(&consumer).await?;

    // Graceful shutdown demonstration
    println!("\nðŸ›‘ Demonstrating graceful shutdown...");
    demonstrate_graceful_shutdown(&consumer, &client).await?;

    println!("âœ… Production consumer example completed successfully");
    Ok(())
}

/// Start comprehensive production monitoring
async fn start_production_monitoring(consumer: &Consumer) {
    let metrics_consumer = consumer.clone();

    tokio::spawn(async move {
        let mut interval = tokio::time::interval(Duration::from_secs(15));

        loop {
            interval.tick().await;

            // Collect comprehensive metrics
            let metrics = metrics_consumer.metrics().await;
            let lag = metrics_consumer.get_lag().await.unwrap_or_default();
            let assigned_partitions = metrics_consumer.assigned_partitions().await;
            let paused_partitions = metrics_consumer.paused_partitions().await;

            // Generate production metrics report
            println!("\nðŸ“Š === PRODUCTION METRICS REPORT ===");
            println!("ðŸ·ï¸  Consumer ID: {}", metrics_consumer.id());
            println!("ðŸ“¡  Topic: {}", metrics_consumer.topic());
            println!("ðŸ‘¥  Consumer Group: {}", metrics_consumer.consumer_group());
            println!(
                "ðŸ“¦  Messages Received: {}",
                metrics.messages_received.load(Ordering::Relaxed)
            );
            println!(
                "âœ…  Messages Processed: {}",
                metrics.messages_processed.load(Ordering::Relaxed)
            );
            println!(
                "âŒ  Messages Failed: {}",
                metrics.messages_failed.load(Ordering::Relaxed)
            );
            println!(
                "ðŸ“  Bytes Received: {} KB",
                metrics.bytes_received.load(Ordering::Relaxed) / 1024
            );

            // Partition information
            println!("ðŸ—‚ï¸  Assigned Partitions: {:?}", assigned_partitions);
            if !paused_partitions.is_empty() {
                println!("â¸ï¸  Paused Partitions: {:?}", paused_partitions);
            }

            // Lag analysis
            let total_lag: u64 = lag.values().sum();
            println!("â±ï¸  Total Consumer Lag: {} messages", total_lag);
            if !lag.is_empty() {
                println!("ðŸ“ˆ  Lag by Partition: {:?}", lag);
            }

            // Processing rate calculation
            let messages_processed = metrics.messages_processed.load(Ordering::Relaxed);
            if messages_processed > 0 {
                println!("âš¡  Processing Rate: ~{} msg/sec", messages_processed / 15);
            }

            // Last activity
            if let Some(last_receive) = *metrics.last_receive_time.read().await {
                let since_last = last_receive.elapsed();
                if since_last.as_secs() > 30 {
                    println!("âš ï¸  Warning: No messages received for {:?}", since_last);
                } else {
                    println!("ðŸ”„  Last Message: {:?} ago", since_last);
                }
            }

            println!("=====================================");
        }
    });
}

/// Demonstrate high-throughput batch processing
async fn demonstrate_batch_processing(consumer: &Consumer) -> Result<()> {
    println!("Processing messages in high-throughput batch mode...");

    let mut processed_count = 0;
    let batch_size = 20;
    let max_batches = 3;

    for batch_num in 1..=max_batches {
        println!("ðŸ“¦ Processing batch {} of {}", batch_num, max_batches);
        let batch_start = std::time::Instant::now();

        let mut batch_messages = Vec::new();

        // Collect batch of messages
        for _ in 0..batch_size {
            if let Some(consumer_message) = consumer.receive().await? {
                batch_messages.push(consumer_message);
            } else {
                break;
            }
        }

        if batch_messages.is_empty() {
            println!("No messages available for batch {}", batch_num);
            continue;
        }

        // Process batch with enhanced error handling
        for (i, consumer_message) in batch_messages.into_iter().enumerate() {
            let message = &consumer_message.message;

            match process_message_with_enhanced_handling(message).await {
                Ok(_) => {
                    consumer_message.ack().await?;
                    processed_count += 1;
                }
                Err(ProcessingError::Retryable) => {
                    println!("   Message {}: Retryable error - will be retried", i + 1);
                    consumer_message.nack().await?;
                }
                Err(ProcessingError::Fatal) => {
                    println!(
                        "   Message {}: Fatal error - acknowledged to prevent retry",
                        i + 1
                    );
                    consumer_message.ack().await?;
                }
                Err(ProcessingError::CircuitBreakerOpen) => {
                    println!(
                        "   Message {}: Circuit breaker open - will retry later",
                        i + 1
                    );
                    consumer_message.nack().await?;
                }
            }
        }

        // Manual commit after successful batch processing
        consumer.commit().await?;

        let batch_duration = batch_start.elapsed();
        println!(
            "   âœ… Batch {} completed in {:?} ({} messages)",
            batch_num, batch_duration, processed_count
        );
    }

    println!(
        "ðŸ“Š Batch processing completed: {} total messages processed",
        processed_count
    );
    Ok(())
}

/// Demonstrate resilient processing with circuit breaker
async fn demonstrate_resilient_processing(consumer: &Consumer) -> Result<()> {
    println!("Demonstrating resilient processing with enhanced error handling...");

    let mut consecutive_failures = 0;
    let max_consecutive_failures = 3;
    let mut messages_processed = 0;

    for i in 1..=15 {
        if let Some(consumer_message) = consumer.receive().await? {
            let message = &consumer_message.message;

            println!("Processing message {} (ID: {})", i, message.id);

            match process_message_with_enhanced_handling(message).await {
                Ok(_) => {
                    println!("   âœ… Successfully processed");
                    consumer_message.ack().await?;
                    consecutive_failures = 0; // Reset failure counter
                    messages_processed += 1;
                }
                Err(ProcessingError::Retryable) => {
                    println!("   âš ï¸ Retryable error - message will be retried");
                    consumer_message.nack().await?;
                    consecutive_failures += 1;
                }
                Err(ProcessingError::Fatal) => {
                    println!("   âŒ Fatal error - message acknowledged to prevent infinite retry");
                    consumer_message.ack().await?;
                    consecutive_failures = 0;
                }
                Err(ProcessingError::CircuitBreakerOpen) => {
                    println!("   ðŸ”´ Circuit breaker protection activated");
                    consumer_message.nack().await?;

                    // Wait for circuit breaker recovery
                    println!("   â±ï¸ Waiting for circuit breaker recovery...");
                    tokio::time::sleep(Duration::from_millis(500)).await;
                    consecutive_failures = 0;
                }
            }

            // Circuit breaker simulation
            if consecutive_failures >= max_consecutive_failures {
                println!("   ðŸ›¡ï¸ Too many consecutive failures, pausing processing");
                tokio::time::sleep(Duration::from_secs(1)).await;
                consecutive_failures = 0;
            }

            // Manual commit every 5 messages for data consistency
            if messages_processed % 5 == 0 && messages_processed > 0 {
                println!(
                    "   ðŸ“ Manual commit at {} processed messages",
                    messages_processed
                );
                consumer.commit().await?;
            }
        } else {
            break;
        }
    }

    println!(
        "ðŸ›¡ï¸ Resilient processing completed: {} messages processed",
        messages_processed
    );
    Ok(())
}

/// Demonstrate advanced partition management
async fn demonstrate_advanced_partition_management(consumer: &Consumer) -> Result<()> {
    println!("Demonstrating advanced partition management...");

    let assigned_partitions = consumer.assigned_partitions().await;
    println!(
        "ðŸ“Š Currently assigned partitions: {:?}",
        assigned_partitions
    );

    if assigned_partitions.is_empty() {
        println!("No partitions assigned, skipping partition management demo");
        return Ok(());
    }

    // Get detailed partition assignment information
    if let Some(assignment) = consumer.partition_assignment().await {
        println!("ðŸ“‹ Partition Assignment Details:");
        println!("   Assignment ID: {}", assignment.assignment_id);
        println!("   Assigned at: {:?}", assignment.assigned_at);
        println!("   Total partitions: {}", assignment.partitions.len());
    }

    // Demonstrate dynamic partition management
    if assigned_partitions.len() > 1 {
        let partition_to_manage = assigned_partitions[0];

        // Pause specific partition
        println!(
            "â¸ï¸ Pausing partition {} for maintenance",
            partition_to_manage
        );
        consumer.pause_partitions(vec![partition_to_manage]).await?;

        let paused = consumer.paused_partitions().await;
        println!("   Currently paused: {:?}", paused);

        // Process from remaining partitions
        println!("ðŸ”„ Processing from active partitions...");
        for _ in 0..3 {
            if let Some(consumer_message) = consumer.receive().await? {
                let message = &consumer_message.message;
                println!(
                    "   Received from partition {}: {}",
                    message.partition, message.id
                );
                consumer_message.ack().await?;
            }
            tokio::time::sleep(Duration::from_millis(100)).await;
        }

        // Resume paused partition
        println!("â–¶ï¸ Resuming partition {}", partition_to_manage);
        consumer
            .resume_partitions(vec![partition_to_manage])
            .await?;

        let paused_after = consumer.paused_partitions().await;
        println!("   Paused after resume: {:?}", paused_after);
    }

    // Show current lag for all partitions
    match consumer.get_lag().await {
        Ok(lag_map) => {
            println!("ðŸ“ˆ Current consumer lag by partition:");
            for (partition, lag) in lag_map {
                println!("   Partition {}: {} messages behind", partition, lag);
            }
        }
        Err(e) => println!("Could not retrieve lag information: {}", e),
    }

    println!("âœ… Advanced partition management completed");
    Ok(())
}

/// Demonstrate performance-optimized streaming
async fn demonstrate_optimized_streaming(consumer: &Consumer) -> Result<()> {
    println!("Demonstrating performance-optimized streaming interface...");

    let mut stream = consumer.stream();
    let mut processed_count = 0;
    let max_stream_messages = 10;
    let start_time = std::time::Instant::now();

    println!("ðŸŒŠ Starting optimized stream processing...");

    while let Some(result) = stream.next().await {
        if processed_count >= max_stream_messages {
            break;
        }

        match result {
            Ok(consumer_message) => {
                let message = &consumer_message.message;

                // High-performance processing simulation
                match process_message_with_enhanced_handling(message).await {
                    Ok(_) => {
                        consumer_message.ack().await?;
                        processed_count += 1;

                        if processed_count % 5 == 0 {
                            let elapsed = start_time.elapsed();
                            let rate = processed_count as f64 / elapsed.as_secs_f64();
                            println!(
                                "   ðŸ“Š Processed {} messages at {:.1} msg/sec",
                                processed_count, rate
                            );
                        }
                    }
                    Err(e) => {
                        println!("   âš ï¸ Stream processing error: {:?}", e);
                        consumer_message.nack().await?;
                    }
                }
            }
            Err(e) => {
                println!("Stream error: {}", e);
                break;
            }
        }
    }

    let total_time = start_time.elapsed();
    let final_rate = processed_count as f64 / total_time.as_secs_f64();

    println!("âš¡ Stream processing completed:");
    println!("   Total messages: {}", processed_count);
    println!("   Total time: {:?}", total_time);
    println!("   Average rate: {:.1} messages/sec", final_rate);

    Ok(())
}

/// Demonstrate production metrics and observability
async fn demonstrate_production_metrics(consumer: &Consumer) -> Result<()> {
    println!("Generating comprehensive production metrics report...");

    // Process some messages to generate metrics
    for i in 1..=10 {
        if let Some(consumer_message) = consumer.receive().await? {
            let message = &consumer_message.message;

            // Simulate different processing outcomes
            match i % 4 {
                0 => {
                    // Simulate failure for metrics
                    consumer_message.nack().await?;
                }
                _ => {
                    consumer_message.ack().await?;
                }
            }
        }
        tokio::time::sleep(Duration::from_millis(50)).await;
    }

    // Generate comprehensive metrics report
    let metrics = consumer.metrics().await;
    let lag = consumer.get_lag().await.unwrap_or_default();
    let assigned_partitions = consumer.assigned_partitions().await;

    println!("\nðŸ“Š === COMPREHENSIVE METRICS REPORT ===");
    println!("Consumer Configuration:");
    println!("   ID: {}", consumer.id());
    println!("   Topic: {}", consumer.topic());
    println!("   Group: {}", consumer.consumer_group());
    println!("   Config: {:?}", consumer.config());

    println!("\nMessage Statistics:");
    println!(
        "   Messages Received: {}",
        metrics.messages_received.load(Ordering::Relaxed)
    );
    println!(
        "   Messages Processed: {}",
        metrics.messages_processed.load(Ordering::Relaxed)
    );
    println!(
        "   Messages Failed: {}",
        metrics.messages_failed.load(Ordering::Relaxed)
    );
    println!(
        "   Bytes Received: {} bytes",
        metrics.bytes_received.load(Ordering::Relaxed)
    );

    println!("\nPartition Information:");
    println!("   Assigned Partitions: {:?}", assigned_partitions);
    println!("   Partition Count: {}", assigned_partitions.len());

    println!("\nLag Analysis:");
    if lag.is_empty() {
        println!("   No lag information available");
    } else {
        let total_lag: u64 = lag.values().sum();
        println!("   Total Lag: {} messages", total_lag);
        println!("   Per-Partition Lag: {:?}", lag);
    }

    // Performance metrics
    if let Some(last_receive) = *metrics.last_receive_time.read().await {
        println!("\nTiming Information:");
        println!("   Last Message Received: {:?} ago", last_receive.elapsed());
    }

    let processing_time = *metrics.processing_time_ms.read().await;
    if processing_time > 0.0 {
        println!("   Average Processing Time: {:.2}ms", processing_time);
    }

    println!("=========================================");

    Ok(())
}

/// Demonstrate graceful shutdown
async fn demonstrate_graceful_shutdown(consumer: &Consumer, client: &RustMqClient) -> Result<()> {
    println!("Initiating graceful shutdown sequence...");

    // Process any remaining messages
    println!("ðŸ”„ Processing remaining messages...");
    let mut final_count = 0;
    let shutdown_timeout = Duration::from_secs(2);
    let shutdown_start = std::time::Instant::now();

    while shutdown_start.elapsed() < shutdown_timeout {
        if let Some(consumer_message) = consumer.receive().await? {
            consumer_message.ack().await?;
            final_count += 1;
        } else {
            break;
        }
    }

    if final_count > 0 {
        println!("   âœ… Processed {} final messages", final_count);
    }

    // Final commit before shutdown
    println!("ðŸ“ Performing final offset commit...");
    consumer.commit().await?;

    // Close consumer with proper cleanup
    println!("ðŸ”’ Closing consumer with proper cleanup...");
    consumer.close().await?;

    // Close client connection
    println!("ðŸ”Œ Closing client connection...");
    client.close().await?;

    println!("âœ… Graceful shutdown completed successfully");
    println!("   All resources properly cleaned up");
    println!("   All offsets committed");
    println!("   No message loss occurred");

    Ok(())
}

/// Enhanced message processing with comprehensive error handling
async fn process_message_with_enhanced_handling(
    message: &Message,
) -> std::result::Result<(), ProcessingError> {
    // Simulate realistic processing time
    tokio::time::sleep(Duration::from_millis(10)).await;

    // Simulate different error conditions based on message content
    let payload = message.payload_as_string().unwrap_or_default();

    if payload.contains("circuit_breaker") {
        Err(ProcessingError::CircuitBreakerOpen)
    } else if payload.contains("fatal_error") {
        Err(ProcessingError::Fatal)
    } else if payload.contains("retry_error") {
        Err(ProcessingError::Retryable)
    } else {
        // Successful processing
        Ok(())
    }
}

/// Enhanced processing error types
#[derive(Debug)]
enum ProcessingError {
    Retryable,
    Fatal,
    CircuitBreakerOpen,
}

impl std::fmt::Display for ProcessingError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ProcessingError::Retryable => write!(f, "Retryable processing error"),
            ProcessingError::Fatal => write!(f, "Fatal processing error"),
            ProcessingError::CircuitBreakerOpen => write!(f, "Circuit breaker is open"),
        }
    }
}

impl std::error::Error for ProcessingError {}
