//! End-to-end integration tests for gRPC protobuf services
//! 
//! This test suite covers complete workflows involving both BrokerReplicationService
//! and ControllerRaftService, testing:
//! - Cross-service communication patterns
//! - Complete replication workflows
//! - Leadership transfer coordination
//! - Partition assignment and removal flows
//! - Network failure simulation and recovery
//! - Performance under load scenarios

use rustmq::{
    types::*,
    proto::{broker, controller, common},
    proto_convert,
    network::grpc_server::BrokerReplicationServiceImpl,
    controller::service::{ControllerService, ControllerRaftServiceImpl},
    replication::{FollowerReplicationHandler, ReplicationManager},
    storage::{DirectIOWal, AlignedBufferPool},
    config::{WalConfig, ScalingConfig, ReplicationConfig},
    error::RustMqError,
};
use std::sync::Arc;
use std::collections::HashMap;
use std::time::Duration;
use tempfile::TempDir;
use tokio::sync::{RwLock, Mutex};
use tokio::time::{timeout, sleep};
use tonic::{Request, Response, Status, transport::Server};
use chrono::Utc;

// Test cluster configuration
#[derive(Clone)]
struct TestCluster {
    controllers: Vec<TestController>,
    brokers: Vec<TestBroker>,
}

struct TestController {
    id: String,
    service: Arc<RwLock<ControllerService>>,
    raft_service: ControllerRaftServiceImpl,
}

struct TestBroker {
    id: String,
    replication_service: BrokerReplicationServiceImpl,
    wal: Arc<DirectIOWal>,
    _temp_dir: TempDir, // Keep alive for WAL directory
}

// Mock network layer for testing
struct MockNetworkLayer {
    controllers: HashMap<String, TestController>,
    brokers: HashMap<String, TestBroker>,
}

impl MockNetworkLayer {
    fn new() -> Self {
        Self {
            controllers: HashMap::new(),
            brokers: HashMap::new(),
        }
    }

    fn add_controller(&mut self, controller: TestController) {
        self.controllers.insert(controller.id.clone(), controller);
    }

    fn add_broker(&mut self, broker: TestBroker) {
        self.brokers.insert(broker.id.clone(), broker);
    }

    async fn send_vote_request(&self, target: &str, request: controller::RequestVoteRequest) 
        -> Result<controller::RequestVoteResponse, Status> {
        if let Some(controller) = self.controllers.get(target) {
            controller.raft_service.request_vote(Request::new(request)).await
                .map(|r| r.into_inner())
        } else {
            Err(Status::not_found(format!("Controller {} not found", target)))
        }
    }

    async fn send_replication_request(&self, target: &str, request: broker::ReplicateDataRequest) 
        -> Result<broker::ReplicateDataResponse, Status> {
        if let Some(broker) = self.brokers.get(target) {
            broker.replication_service.replicate_data(Request::new(request)).await
                .map(|r| r.into_inner())
        } else {
            Err(Status::not_found(format!("Broker {} not found", target)))
        }
    }
}

// Helper functions for creating test components
async fn create_test_controller(id: String) -> TestController {
    let scaling_config = ScalingConfig {
        max_concurrent_additions: 3,
        max_concurrent_decommissions: 1,
        rebalance_timeout_ms: 300_000,
        traffic_migration_rate: 0.1,
        health_check_timeout_ms: 30_000,
    };

    let controller_service = ControllerService::new(id.clone(), vec![], scaling_config);
    let service_arc = Arc::new(RwLock::new(controller_service));
    let raft_service = ControllerRaftServiceImpl::new(service_arc.clone());

    TestController {
        id,
        service: service_arc,
        raft_service,
    }
}

async fn create_test_broker(id: String) -> TestBroker {
    let temp_dir = TempDir::new().unwrap();
    let wal_config = WalConfig {
        path: temp_dir.path().to_path_buf(),
        capacity_bytes: 1024 * 1024,
        fsync_on_write: false,
        segment_size_bytes: 64 * 1024,
        buffer_size: 4096,
        upload_interval_ms: 60_000,
        flush_interval_ms: 1000,
    };

    let buffer_pool = Arc::new(AlignedBufferPool::new(4096, 10));
    let wal = Arc::new(DirectIOWal::new(wal_config, buffer_pool).await.unwrap());
    let replication_service = BrokerReplicationServiceImpl::new(id.clone());

    TestBroker {
        id,
        replication_service,
        wal,
        _temp_dir: temp_dir,
    }
}

fn test_topic_partition() -> TopicPartition {
    TopicPartition {
        topic: "integration-test-topic".to_string(),
        partition: 0,
    }
}

fn test_record_batch(count: usize) -> Vec<WalRecord> {
    (0..count).map(|i| WalRecord {
        topic_partition: test_topic_partition(),
        offset: i as u64,
        record: Record {
            key: Some(format!("key-{}", i).into_bytes()),
            value: format!("value-{}", i).into_bytes(),
            headers: vec![Header {
                key: "batch-id".to_string(),
                value: "integration-test".as_bytes().to_vec(),
            }],
            timestamp: Utc::now().timestamp_millis(),
        },
        crc32: 12345 + i as u32,
    }).collect()
}

// ============================================================================
// Basic Integration Tests
// ============================================================================

#[tokio::test]
async fn test_controller_cluster_formation() {
    let mut network = MockNetworkLayer::new();
    
    // Create 3 controllers for a Raft cluster
    let controller1 = create_test_controller("controller-1".to_string()).await;
    let controller2 = create_test_controller("controller-2".to_string()).await;
    let controller3 = create_test_controller("controller-3".to_string()).await;

    network.add_controller(controller1);
    network.add_controller(controller2);
    network.add_controller(controller3);

    // Test initial vote request from controller-1
    let vote_request = controller::RequestVoteRequest {
        term: 1,
        candidate_id: "controller-1".to_string(),
        last_log_index: 0,
        last_log_term: 0,
        pre_vote: false,
        metadata: None,
        candidate_priority: 100,
        candidate_version: "1.0.0".to_string(),
        candidate_capabilities: vec!["consensus".to_string()],
        election_reason: "startup_election".to_string(),
        election_timeout_ms: 5000,
    };

    // Send vote request to controller-2
    let response = network.send_vote_request("controller-2", vote_request.clone()).await;
    assert!(response.is_ok());
    let vote_response = response.unwrap();
    assert_eq!(vote_response.voter_id, "controller-2");

    // Send vote request to controller-3
    let response = network.send_vote_request("controller-3", vote_request).await;
    assert!(response.is_ok());
    let vote_response = response.unwrap();
    assert_eq!(vote_response.voter_id, "controller-3");
}

#[tokio::test]
async fn test_broker_replication_workflow() {
    let mut network = MockNetworkLayer::new();
    
    // Create leader and follower brokers
    let leader_broker = create_test_broker("leader-broker".to_string()).await;
    let follower_broker = create_test_broker("follower-broker".to_string()).await;

    network.add_broker(leader_broker);
    network.add_broker(follower_broker);

    // Create test replication request
    let records = test_record_batch(5);
    let proto_records: Result<Vec<_>, _> = records.into_iter()
        .map(|r| r.try_into())
        .collect();
    assert!(proto_records.is_ok());

    let replication_request = broker::ReplicateDataRequest {
        leader_epoch: 1,
        topic_partition: Some(test_topic_partition().into()),
        records: proto_records.unwrap(),
        leader_id: "leader-broker".to_string(),
        leader_high_watermark: 5,
        request_id: 12345,
        metadata: None,
        batch_base_offset: 0,
        batch_record_count: 5,
        batch_size_bytes: 1024,
        compression: common::CompressionType::None as i32,
    };

    // Send replication request to follower
    let response = network.send_replication_request("follower-broker", replication_request).await;
    // Will fail because no handler is registered, but should not panic
    assert!(response.is_err());
}

#[tokio::test]
async fn test_heartbeat_sequence() {
    let mut network = MockNetworkLayer::new();
    
    let leader_broker = create_test_broker("leader-1".to_string()).await;
    let follower_broker = create_test_broker("follower-1".to_string()).await;

    network.add_broker(leader_broker);
    network.add_broker(follower_broker);

    // Send series of heartbeats
    for i in 0..5 {
        let heartbeat_request = broker::HeartbeatRequest {
            leader_epoch: 1,
            leader_id: "leader-1".to_string(),
            topic_partition: Some(test_topic_partition().into()),
            high_watermark: i * 10,
            metadata: None,
            leader_log_end_offset: i * 10 + 5,
            in_sync_replicas: vec!["leader-1".to_string(), "follower-1".to_string()],
            heartbeat_interval_ms: 30000,
            leader_messages_per_second: 100,
            leader_bytes_per_second: 1024 * 100,
        };

        // This will fail without proper handler setup, but tests the protocol
        let response = network.brokers.get("follower-1").unwrap()
            .replication_service
            .send_heartbeat(Request::new(heartbeat_request))
            .await;
        
        assert!(response.is_err()); // Expected without handler
    }
}

// ============================================================================
// Complex Workflow Tests
// ============================================================================

#[tokio::test]
async fn test_partition_assignment_workflow() {
    let mut network = MockNetworkLayer::new();
    
    // Create controller and broker
    let controller = create_test_controller("controller-1".to_string()).await;
    let broker = create_test_broker("broker-1".to_string()).await;

    network.add_controller(controller);
    network.add_broker(broker);

    // Simulate partition assignment from controller to broker
    let assignment_request = broker::AssignPartitionRequest {
        topic_partition: Some(test_topic_partition().into()),
        replica_set: vec!["broker-1".to_string(), "broker-2".to_string()],
        leader_id: "broker-1".to_string(),
        leader_epoch: 1,
        controller_id: "controller-1".to_string(),
        metadata: None,
        controller_epoch: 1,
        assignment_reason: "initial_assignment".to_string(),
        topic_config: None,
        initial_offset: 0,
        is_new_partition: true,
        expected_throughput_mbs: 10,
        priority: 1,
    };

    let response = network.brokers.get("broker-1").unwrap()
        .replication_service
        .assign_partition(Request::new(assignment_request))
        .await;
    
    // Will fail without proper setup, but tests protocol flow
    assert!(response.is_err());
}

#[tokio::test]
async fn test_leadership_transfer_coordination() {
    let mut network = MockNetworkLayer::new();
    
    // Create 3 brokers for leadership transfer
    let current_leader = create_test_broker("current-leader".to_string()).await;
    let new_leader = create_test_broker("new-leader".to_string()).await;
    let follower = create_test_broker("follower".to_string()).await;

    network.add_broker(current_leader);
    network.add_broker(new_leader);
    network.add_broker(follower);

    // Test leadership transfer request
    let transfer_request = broker::TransferLeadershipRequest {
        topic_partition: Some(test_topic_partition().into()),
        current_leader_id: "current-leader".to_string(),
        current_leader_epoch: 5,
        new_leader_id: "new-leader".to_string(),
        metadata: None,
        controller_id: "controller-1".to_string(),
        controller_epoch: 1,
        transfer_timeout_ms: 30000,
        force_transfer: false,
        wait_for_sync: true,
    };

    // Send to current leader (should coordinate transfer)
    let response = network.brokers.get("current-leader").unwrap()
        .replication_service
        .transfer_leadership(Request::new(transfer_request))
        .await;
    
    assert!(response.is_err()); // Expected without full setup
}

#[tokio::test]
async fn test_cluster_scaling_workflow() {
    let mut network = MockNetworkLayer::new();
    
    // Create initial cluster
    let controller = create_test_controller("controller-1".to_string()).await;
    let broker1 = create_test_broker("broker-1".to_string()).await;
    let broker2 = create_test_broker("broker-2".to_string()).await;

    network.add_controller(controller);
    network.add_broker(broker1);
    network.add_broker(broker2);

    // Test adding new node to controller cluster
    let add_node_request = controller::AddNodeRequest {
        node_id: "new-broker-3".to_string(),
        node_address: "192.168.1.103:9090".to_string(),
        voting_member: true,
        metadata: None,
        capabilities: vec!["replication".to_string()],
        priority: 100,
        version: "1.0.0".to_string(),
    };

    let response = network.controllers.get("controller-1").unwrap()
        .raft_service
        .add_node(Request::new(add_node_request))
        .await;
    
    assert!(response.is_ok());

    // Create the new broker
    let new_broker = create_test_broker("new-broker-3".to_string()).await;
    network.add_broker(new_broker);

    // Test partition assignment to new broker
    let assignment_request = broker::AssignPartitionRequest {
        topic_partition: Some(TopicPartition {
            topic: "new-topic".to_string(),
            partition: 0,
        }.into()),
        replica_set: vec!["broker-1".to_string(), "new-broker-3".to_string()],
        leader_id: "broker-1".to_string(),
        leader_epoch: 1,
        controller_id: "controller-1".to_string(),
        metadata: None,
        controller_epoch: 1,
        assignment_reason: "scaling_assignment".to_string(),
        topic_config: None,
        initial_offset: 0,
        is_new_partition: true,
        expected_throughput_mbs: 5,
        priority: 1,
    };

    let response = network.brokers.get("new-broker-3").unwrap()
        .replication_service
        .assign_partition(Request::new(assignment_request))
        .await;
    
    assert!(response.is_err()); // Expected without full handler setup
}

// ============================================================================
// Error Handling and Recovery Tests
// ============================================================================

#[tokio::test]
async fn test_network_partition_simulation() {
    let mut network = MockNetworkLayer::new();
    
    // Create 3 controllers
    let controller1 = create_test_controller("controller-1".to_string()).await;
    let controller2 = create_test_controller("controller-2".to_string()).await;
    let controller3 = create_test_controller("controller-3".to_string()).await;

    network.add_controller(controller1);
    network.add_controller(controller2);
    network.add_controller(controller3);

    // Simulate network partition - controller-1 can't reach others
    let vote_request = controller::RequestVoteRequest {
        term: 2,
        candidate_id: "controller-1".to_string(),
        last_log_index: 5,
        last_log_term: 1,
        pre_vote: false,
        metadata: None,
        candidate_priority: 100,
        candidate_version: "1.0.0".to_string(),
        candidate_capabilities: vec![],
        election_reason: "partition_recovery".to_string(),
        election_timeout_ms: 5000,
    };

    // Should still be able to send to reachable nodes
    let response = network.send_vote_request("controller-2", vote_request.clone()).await;
    assert!(response.is_ok());

    // Test pre-vote optimization during partition
    let pre_vote_request = controller::PreVoteRequest {
        term: 3,
        candidate_id: "controller-1".to_string(),
        last_log_index: 5,
        last_log_term: 1,
        metadata: None,
        election_reason: "partition_pre_vote".to_string(),
        leader_lease_timeout_ms: 10000,
        last_leader_contact: Some(prost_types::Timestamp {
            seconds: Utc::now().timestamp() - 15, // 15 seconds ago
            nanos: 0,
        }),
        candidate_capabilities: vec![],
        candidate_priority: 100,
    };

    let response = network.controllers.get("controller-2").unwrap()
        .raft_service
        .pre_vote(Request::new(pre_vote_request))
        .await;
    
    assert!(response.is_ok());
}

#[tokio::test]
async fn test_stale_epoch_handling() {
    let mut network = MockNetworkLayer::new();
    
    let leader_broker = create_test_broker("leader".to_string()).await;
    let follower_broker = create_test_broker("follower".to_string()).await;

    network.add_broker(leader_broker);
    network.add_broker(follower_broker);

    // Send replication with stale epoch
    let stale_request = broker::ReplicateDataRequest {
        leader_epoch: 1, // Stale epoch
        topic_partition: Some(test_topic_partition().into()),
        records: vec![],
        leader_id: "old-leader".to_string(),
        leader_high_watermark: 100,
        request_id: 12345,
        metadata: None,
        batch_base_offset: 0,
        batch_record_count: 0,
        batch_size_bytes: 0,
        compression: common::CompressionType::None as i32,
    };

    let response = network.send_replication_request("follower", stale_request).await;
    assert!(response.is_err());

    // Send replication with current epoch
    let current_request = broker::ReplicateDataRequest {
        leader_epoch: 5, // Current epoch
        topic_partition: Some(test_topic_partition().into()),
        records: vec![],
        leader_id: "current-leader".to_string(),
        leader_high_watermark: 200,
        request_id: 12346,
        metadata: None,
        batch_base_offset: 100,
        batch_record_count: 0,
        batch_size_bytes: 0,
        compression: common::CompressionType::None as i32,
    };

    let response = network.send_replication_request("follower", current_request).await;
    assert!(response.is_err()); // Still fails without handler, but processes epoch
}

// ============================================================================
// Performance and Load Tests
// ============================================================================

#[tokio::test]
async fn test_high_throughput_replication() {
    let mut network = MockNetworkLayer::new();
    
    let leader_broker = create_test_broker("leader".to_string()).await;
    let follower_broker = create_test_broker("follower".to_string()).await;

    network.add_broker(leader_broker);
    network.add_broker(follower_broker);

    // Send many concurrent replication requests
    let mut handles = Vec::new();
    
    for batch_id in 0..10 {
        let network_ref = &network;
        let handle = tokio::spawn(async move {
            let records = test_record_batch(100); // 100 records per batch
            let proto_records: Vec<_> = records.into_iter()
                .map(|r| r.try_into().unwrap())
                .collect();

            let request = broker::ReplicateDataRequest {
                leader_epoch: 1,
                topic_partition: Some(TopicPartition {
                    topic: format!("topic-{}", batch_id),
                    partition: 0,
                }.into()),
                records: proto_records,
                leader_id: "leader".to_string(),
                leader_high_watermark: 100,
                request_id: batch_id as u64,
                metadata: None,
                batch_base_offset: batch_id as u64 * 100,
                batch_record_count: 100,
                batch_size_bytes: 10240,
                compression: common::CompressionType::Lz4 as i32,
            };

            network_ref.send_replication_request("follower", request).await
        });
        handles.push(handle);
    }

    // Wait for all requests to complete
    for handle in handles {
        let result = handle.await.unwrap();
        // All will fail without handlers, but should not panic or timeout
        assert!(result.is_err());
    }
}

#[tokio::test]
async fn test_large_log_entries() {
    let network = MockNetworkLayer::new();
    
    let controller = create_test_controller("controller-1".to_string()).await;
    
    // Create large log entry
    let large_data = vec![0u8; 1_000_000]; // 1MB entry
    let log_entry = controller::LogEntry {
        index: 1,
        term: 1,
        r#type: controller::LogEntryType::BrokerMetadata as i32,
        data: large_data,
        timestamp: Some(prost_types::Timestamp {
            seconds: Utc::now().timestamp(),
            nanos: 0,
        }),
        node_id: "controller-1".to_string(),
        checksum: 12345,
        data_size: 1_000_000,
        correlation_id: "large-entry-test".to_string(),
        priority: 0,
        tags: vec!["performance-test".to_string()],
    };

    let append_request = controller::AppendEntriesRequest {
        term: 1,
        leader_id: "controller-1".to_string(),
        prev_log_index: 0,
        prev_log_term: 0,
        entries: vec![log_entry],
        leader_commit: 0,
        metadata: None,
        is_heartbeat: false,
        batch_size: 1,
        total_batch_size_bytes: 1_000_000,
        leader_log_size: 1_000_000,
        leader_snapshot_index: 0,
        max_entries_per_request: 10,
        max_bytes_per_request: 2_000_000,
    };

    let start = std::time::Instant::now();
    let response = controller.raft_service
        .append_entries(Request::new(append_request))
        .await;
    let duration = start.elapsed();

    assert!(response.is_ok());
    assert!(duration.as_millis() < 1000); // Should handle large entries efficiently
}

#[tokio::test]
async fn test_snapshot_installation_workflow() {
    let network = MockNetworkLayer::new();
    
    let controller = create_test_controller("follower-controller".to_string()).await;
    
    // Simulate snapshot installation in chunks
    let snapshot_data = vec![1u8; 100_000]; // 100KB snapshot
    let chunk_size = 10_000; // 10KB chunks
    let total_chunks = (snapshot_data.len() + chunk_size - 1) / chunk_size;

    for chunk_idx in 0..total_chunks {
        let start_offset = chunk_idx * chunk_size;
        let end_offset = std::cmp::min(start_offset + chunk_size, snapshot_data.len());
        let chunk = &snapshot_data[start_offset..end_offset];
        let is_final = chunk_idx == total_chunks - 1;

        let snapshot_request = controller::InstallSnapshotRequest {
            term: 1,
            leader_id: "leader-controller".to_string(),
            last_included_index: 1000,
            last_included_term: 1,
            offset: start_offset as u64,
            data: chunk.to_vec(),
            done: is_final,
            metadata: None,
            snapshot_size_bytes: snapshot_data.len() as u64,
            chunk_size_bytes: chunk.len() as u32,
            chunk_index: chunk_idx as u32,
            total_chunks: total_chunks as u32,
            snapshot_id: "test-snapshot-123".to_string(),
            snapshot_checksum: 54321,
            snapshot_timestamp: Some(prost_types::Timestamp {
                seconds: Utc::now().timestamp(),
                nanos: 0,
            }),
            compression: common::CompressionType::None as i32,
            uncompressed_size: chunk.len() as u64,
        };

        let response = controller.raft_service
            .install_snapshot(Request::new(snapshot_request))
            .await;
        
        assert!(response.is_ok());
        let snapshot_response = response.unwrap().into_inner();
        assert_eq!(snapshot_response.follower_id, "follower-controller");
    }
}

// ============================================================================
// Timeout and Cancellation Tests
// ============================================================================

#[tokio::test]
async fn test_request_timeouts() {
    let network = MockNetworkLayer::new();
    
    let controller = create_test_controller("controller-1".to_string()).await;
    
    // Test with short timeout
    let vote_request = controller::RequestVoteRequest {
        term: 1,
        candidate_id: "controller-1".to_string(),
        last_log_index: 0,
        last_log_term: 0,
        pre_vote: false,
        metadata: Some(common::RequestMetadata {
            request_id: "timeout-test".to_string(),
            timestamp: Some(prost_types::Timestamp {
                seconds: Utc::now().timestamp(),
                nanos: 0,
            }),
            client_id: "test-client".to_string(),
            timeout_ms: 100, // Very short timeout
            retry_count: 0,
            correlation_id: "timeout-corr".to_string(),
            source_broker_id: "source".to_string(),
            target_broker_id: "target".to_string(),
            operation_type: "vote".to_string(),
            priority: 1,
            trace_context: HashMap::new(),
        }),
        candidate_priority: 100,
        candidate_version: "1.0.0".to_string(),
        candidate_capabilities: vec![],
        election_reason: "timeout_test".to_string(),
        election_timeout_ms: 100,
    };

    // Should complete quickly
    let result = timeout(Duration::from_millis(500), 
        controller.raft_service.request_vote(Request::new(vote_request))
    ).await;
    
    assert!(result.is_ok());
}

#[tokio::test]
async fn test_concurrent_operations() {
    let mut network = MockNetworkLayer::new();
    
    let controller = create_test_controller("controller-1".to_string()).await;
    let broker = create_test_broker("broker-1".to_string()).await;

    network.add_controller(controller);
    network.add_broker(broker);

    // Run multiple operations concurrently
    let mut handles = Vec::new();

    // Vote requests
    for i in 0..5 {
        let network_ref = &network;
        let handle = tokio::spawn(async move {
            let request = controller::RequestVoteRequest {
                term: i + 1,
                candidate_id: format!("candidate-{}", i),
                last_log_index: i,
                last_log_term: 1,
                pre_vote: false,
                metadata: None,
                candidate_priority: 100,
                candidate_version: "1.0.0".to_string(),
                candidate_capabilities: vec![],
                election_reason: "concurrent_test".to_string(),
                election_timeout_ms: 5000,
            };
            network_ref.send_vote_request("controller-1", request).await
        });
        handles.push(handle);
    }

    // Replication requests
    for i in 0..5 {
        let network_ref = &network;
        let handle = tokio::spawn(async move {
            let request = broker::ReplicateDataRequest {
                leader_epoch: 1,
                topic_partition: Some(TopicPartition {
                    topic: format!("concurrent-topic-{}", i),
                    partition: 0,
                }.into()),
                records: vec![],
                leader_id: "leader".to_string(),
                leader_high_watermark: i,
                request_id: i,
                metadata: None,
                batch_base_offset: 0,
                batch_record_count: 0,
                batch_size_bytes: 0,
                compression: common::CompressionType::None as i32,
            };
            network_ref.send_replication_request("broker-1", request).await
        });
        handles.push(handle);
    }

    // Wait for all operations to complete
    for handle in handles {
        let _result = handle.await.unwrap();
        // Results may vary, but should not panic
    }
}

// ============================================================================
// Configuration and Metadata Tests
// ============================================================================

#[tokio::test]
async fn test_metadata_propagation() {
    let network = MockNetworkLayer::new();
    
    let controller = create_test_controller("controller-1".to_string()).await;
    
    // Test with rich metadata
    let metadata = common::RequestMetadata {
        request_id: "metadata-test-123".to_string(),
        timestamp: Some(prost_types::Timestamp {
            seconds: Utc::now().timestamp(),
            nanos: 0,
        }),
        client_id: "integration-test-client".to_string(),
        timeout_ms: 30000,
        retry_count: 2,
        correlation_id: "integration-corr-456".to_string(),
        source_broker_id: "source-broker".to_string(),
        target_broker_id: "target-broker".to_string(),
        operation_type: "consensus".to_string(),
        priority: 1,
        trace_context: {
            let mut map = HashMap::new();
            map.insert("trace-id".to_string(), "trace-789".to_string());
            map.insert("span-id".to_string(), "span-012".to_string());
            map
        },
    };

    let cluster_info_request = controller::GetClusterInfoRequest {
        metadata: Some(metadata),
        include_node_details: true,
        include_log_info: true,
        include_performance_metrics: true,
    };

    let response = controller.raft_service
        .get_cluster_info(Request::new(cluster_info_request))
        .await;
    
    assert!(response.is_ok());
    let cluster_response = response.unwrap().into_inner();
    
    // Verify metadata is processed
    assert!(cluster_response.metadata.is_some());
    let response_metadata = cluster_response.metadata.unwrap();
    assert!(!response_metadata.request_id.is_empty());
}

#[tokio::test]
async fn test_version_compatibility() {
    let network = MockNetworkLayer::new();
    
    let controller = create_test_controller("controller-1".to_string()).await;
    
    // Test with different version strings
    let versions = vec![
        "1.0.0",
        "2.0.0-beta",
        "1.5.3-rc1",
        "dev-build",
    ];

    for version in versions {
        let vote_request = controller::RequestVoteRequest {
            term: 1,
            candidate_id: "version-test".to_string(),
            last_log_index: 0,
            last_log_term: 0,
            pre_vote: false,
            metadata: None,
            candidate_priority: 100,
            candidate_version: version.to_string(),
            candidate_capabilities: vec!["replication".to_string(), "consensus".to_string()],
            election_reason: "version_compatibility_test".to_string(),
            election_timeout_ms: 5000,
        };

        let response = controller.raft_service
            .request_vote(Request::new(vote_request))
            .await;
        
        assert!(response.is_ok(), "Version {} should be handled", version);
    }
}